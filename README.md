# Flappy Bird DQN

This is a repo that implements DQN (from scratch) and for it to learn on Flappy Bird, specifically the PyGame/PLE implementation

In its current iteration, I get the following performance averaged over 20 episodes:

| Algorithm | Performance |
| :----:       | :----:         |
| DQN Vanilla  | 119.1   |

The default arguments are the parameters I used to train to get this

## TODO:
* Implement some of Rainbow (see spinning up)
* Fork and add more
    * Games (Pong, OpenAI Gym)
    * Algorithms (A2C, PPO, etc.)
